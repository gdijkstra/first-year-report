\documentclass[a4paper,10pt]{report}

%include report.fmt

\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}


%% Encoding, font stuff
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=10,shrink=10,protrusion=trues]{microtype}
\usepackage{tgpagella}

%% Symbols and whatever
\usepackage{amsmath,amsthm,amssymb,stmaryrd}

%% Layout stuff and other related goodies.
%\usepackage[firstpage]{draftwatermark} % DRAFT only obviously
\usepackage[parfill]{parskip}
\usepackage{xspace}
\usepackage{todonotes}
\setcounter{tocdepth}{1}


%% URLs and other link stuff
\usepackage{url}
\usepackage{hyperref}
\usepackage[noabbrev]{cleveref}

\hypersetup{
  colorlinks,
  citecolor=DarkBlue,
  linkcolor=black,
  urlcolor=DarkBlue}


% Bibliography stuff
\usepackage[autostyle]{csquotes}

\usepackage[
    backend=biber,
    bibstyle=numeric,
    citestyle=authoryear,
    natbib=true,
    hyperref=true,
    url=false, 
    doi=true,
    eprint=false
]{biblatex}
\addbibresource{latex-base/refs.bib}

\input{latex-base/fixbib.tex}

%% Tikz setup
\usepackage{tikz}
\usetikzlibrary{decorations.pathmorphing} % for snake lines
\usetikzlibrary{matrix}
% TikZ styles for drawing

\tikzstyle{snakeline} = [->, decorate, decoration={zigzag, pre length=0.1cm, post length=0.1cm, segment length=1.5mm, amplitude=.25mm}]
\tikzstyle{snakelin} = [->, decoration={zigzag, pre length=0.1cm, post length=0.1cm, segment length=1.5mm, amplitude=.25mm}]
\tikzset{node distance=2cm, auto}

%% Commands
\newcommand{\todoi}[1]{\todo[inline]{#1}}
\newcommand{\withoutk}{\xspace\verb+--without-K+\xspace}
\newcommand{\uip}{uniqueness of identity proofs\xspace}
\newcommand{\Uip}{Uniqueness of identity proofs\xspace}
\newcommand{\hott}{homotopy type theory\xspace}
\newcommand{\Hott}{Homotopy type theory\xspace}
\newcommand{\mltt}{Martin-L\"of's type theory\xspace}
\newcommand{\hit}{higher inductive type\xspace}
\newcommand{\Hit}{Higher inductive type\xspace}
\newcommand{\hits}{higher inductive types\xspace}
\newcommand{\Hits}{Higher inductive types\xspace}
\newcommand{\oit}{ordinary inductive type\xspace}
\newcommand{\Oit}{Ordinary inductive type\xspace}
\newcommand{\oits}{ordinary inductive types\xspace}
\newcommand{\Oits}{Ordinary inductive types\xspace}
\newcommand{\zeroconstructor}{$0$-constructor\xspace}
\newcommand{\zeroconstructors}{$0$-constructors\xspace}
\newcommand{\onehit}{$1$-HIT\xspace}
\newcommand{\onehits}{$1$-HITs\xspace}
\newcommand{\oneconstructor}{$1$-constructor\xspace}
\newcommand{\oneconstructors}{$1$-constructors\xspace}
\newcommand{\twohit}{$2$-HIT\xspace}
\newcommand{\twohits}{$2$-HITs\xspace}
\newcommand{\twoconstructor}{$2$-constructor\xspace}
\newcommand{\twoconstructors}{$2$-constructors\xspace}
\newcommand{\ie}{i.e.\xspace}
\newcommand{\eg}{e.g.\xspace}

\newenvironment{researchdir}{\textbf{Research direction}:\xspace}{}

% Path composition from The Book.
\newcommand{\ct}{%
  \mathchoice{\mathbin{\raisebox{0.5ex}{$\displaystyle\centerdot$}}}%
             {\mathbin{\raisebox{0.5ex}{$\centerdot$}}}%
             {\mathbin{\raisebox{0.25ex}{$\scriptstyle\,\centerdot\,$}}}%
             {\mathbin{\raisebox{0.1ex}{$\scriptscriptstyle\,\centerdot\,$}}}
}

\title{Pattern matching in homotopy type theory}

\author{First year report \\\\ Gabe Dijkstra}

\date{\today}

\begin{document}

\maketitle

\tableofcontents

\chapter*{Preface}
\label{ch:preface}
\addcontentsline{toc}{chapter}{Preface}

This report documents some of the things I have been looking at in the
first year of my PhD, along with future research directions. As the
title suggests, the subjects of study all have to do with pattern
matching and \hott. There is the justification of forms of (dependent)
pattern matching using the terminology of \hott, but there is also the
exploration of new forms of pattern matching on the \hits that \hott
brings to the table.

\Cref{ch:homotopy-type-theory} introduces some of the basic
terminology and notation used throughout the report. Before one can
talk about pattern matching on \hits, one needs a more refined
definition of what these are, which is done in
\cref{ch:hit}. In this chapter, the concept is introduced by
giving several examples. We then try to give formal definitions of a
restricted version of \hits, the so-called \onehits.

\Cref{ch:patmatch} discusses dependent pattern matching, how it
is at odds with \hott in its original form and how one can restrict the
notion to get something that is consistent with \hott. We hope to
eventually give an (internal) account of dependent pattern matching
and hope to give a semantic explanation of the concept using the
language of \hott.

The report is concluded in \cref{cha:phd-outline}, which gives a
summary of the research directions along with a tentative outline of
my PhD thesis and a planning of next academic year.

\chapter{Homotopy type theory}
\label{ch:homotopy-type-theory}

\Hott studies the correspondence between homotopy theory and type
theory. To explain what the correspondence is, we first need to define
the notion of equality internal to type theory: \emph{propositional
  equality}. Propositional equality can be defined in type theory as
the inductive family |Eq : (X : Type0) -> X -> X -> Type0|, with
constructor\footnote{Following Agda's syntax, curly braces around an
  argument indicate that it is an \emph{implicit} argument. The
  argument can be left out when calling the function, as its value can
  be inferred from the other arguments.}:

\begin{itemize}
\item |refl : {X : Type0} {x : X} -> Eq X x x|
\end{itemize}

We will usually denote |Eq A x y| by |x == y|, leaving the type
argument implicit. The type |Eq| comes equipped with an elimination
principle, often called the |J| rule:

\begin{code}
  J  :   (A : Type0)
     ->  (P : (x y : A) -> (p : Id A x y) -> Type0)
     ->  (c : (x : A) -> P x x refl)
     ->  (x y : A) -> (p : Id A x y)
     ->  P x y p
\end{code}

with computation rule:

\begin{code}
  J A P c x x refl = c x
\end{code}


Using |J|, one can show that the relation given by |Eq| is an equality
relation, \ie we have terms of the following types, for any |X :
Type0|:

\begin{itemize}
\item |refl : x == x| for any |x : X|
\item |sym : x == y -> y == x| for any |x y : X|
\item |trans' : x == y -> y == z -> x == z| for any |x y z : X|
\end{itemize}

\newpage

One can also show that the equivalence class operations give us a
groupoid: transitivity is associative, symmetry acts as an inverse
operation and reflexivity is the unit for transitivity. However, the
groupoid laws of propositional equalities on some type |X : Type0|
hold only up to propositional equality, and so on: we do not really
get a groupoid, but an $\omega$-groupoid. These $\omega$-groupoids
also occur in homotopy theory: two points in a space may be connected
by a path, paths may be inverted, composed and there is always a
constant path from a point to itself. One can consider ``paths''
between paths, namely homotopies, which continuous deformations
transforming one path into the other. One can show that the operations
on paths follow the same laws as |refl|, |sym| and |trans'| do, up to
homotopy. This observation leads us to the following correspondence:

\begin{center}%
\begin{tabular}{||l||l||}%
\hline%
 \textbf{type theory}  &  \textbf{homotopy theory}  \\%
\hline%
 |A| is a type                    &  |A| is a space                              \\%
 |x, y : A|                       &  |x| and |y| are points in |A|               \\%
 |p, q : x == y|                  &  |p| and |q| are paths from |x| to |y|       \\%
 |w : p == q|                     &  |w| is a homotopy between paths |p| and |q| \\%
 \multicolumn{1}{||c||}{$\vdots$} & \multicolumn{1}{||c||}{$\vdots$}             \\%
\hline%
\end{tabular}%
\end{center}%

Other important properties of propositional equality is that every
function defined in type theory respects these equalities\footnote{The
  name |ap| stands for ``action (of |f|) on paths'': one can consider
  functions to be functors, as provide a mapping between points and a
  mapping between morphisms, namely the paths, which respects the
  identity path and path composition. |ap| can also be interpreted as
  the ``application (of |f|) to paths''}:

\begin{code}
  ap : {A B : Type0} -> (f : A -> B) -> {x y : A} -> x == y -> f x == f y
\end{code}

If we try to generalise the argument |f : A -> B| to its dependent
form |f : (a : A) -> B a|, we run into trouble comparing |f x| with |f
y|, as they have different types. However, if we have a proof that |x
== y|, we can define a function |B x -> B y|:

\begin{code}
  transport  :   (A : Type0)
                 (B : A -> Type0)
                 (x y : A)
                 (p : x eqA y)
             ->  B x -> B y
\end{code}

Using |transport| we can transform the left hand side to something of
type |B y|, so we can compare the two. The notation for |transport A B
x y p u == v| is |u == v [B down p]|. We can now define the dependent
version of |ap|:

\begin{code}
  apd  :   {A : Type0} {B : A -> Type0} {x y : A} 
       ->  (f : (a : A) -> B a) -> (p : x == y)
       ->  f x == f y [B down p]
\end{code}

As we have already seen, we are following Agda's notation for
$\Pi$-types, \ie |(a : A) -> B a| denotes |Pi A (\a -> B a)|. For
$\Sigma$-types we will use the notation |(a : A) times B a| for |Sig A
(\a -> B a)| to improve readability when dealing with nested
$\Sigma$-types. A function out of the empty type is denoted by
|exfalso : {A : Type0} -> 0 -> A|.

\chapter{Higher inductive types}
\label{ch:hit}

\Hott teaches us that we can regard types as topological spaces up to
homotopy. This leads us to the question of how we can represent
familiar spaces such as the circle and the torus in a type theoretic
way. To be able to describe such types, \hits have been proposed. So
far examples of what these may be have been successfully used to do
homotopy theory \parencite{UFP2013}. However, the applications of
\hits are not limited to homotopy theory: instances have also been
used to model set theory \parencite{Rijke2013} and also to model
versioning systems \parencite{Angiuli2014}.

Even though there is some intuition on what constitutes a \hit and
what its semantics ought to be \parencite{Lumsdaine2013}, a formal
scheme of the general syntax of \hit definitions has not been devised
as of yet. The aim of this chapter is to work towards such a general
syntax by finding a universal construction for \hits akin to how
W-types describe \oits. We start of in \cref{sec:examples} by giving
some examples of \hits. \Cref{sec:containers} explains containers and
their initial algebras (W-types) as a means of describing \oits. It
also explains some of the machinery we need for
\cref{sec:construction-onehits} in which we give a construction of
\onehits. In \cref{sec:construction-2-hits} we explore the idea of
constructing \twohits and discuss some of the tools we need for
that. The chapter is concluded by \cref{sec:high-induct-recurs}, where
we propose an extension of \onehits to \emph{inductive-recursive
  \onehits}, along with an application of this idea.

\newpage

\section{Examples}
\label{sec:examples}

\subsection{Circle}

The idea of \hits is that apart from providing ways of constructing
points, we also provide ways of constructing paths. For example, the
circle can be defined as the type generated by one point and one
non-trivial loop on that point: we define |Circle| to be the type with:

\begin{itemize}
\item a \emph{point} constructor |base : Circle|
\item a \emph{path} constructor |loop : base == base|
\end{itemize}

In order to eliminate out of this type, we need to provide a point in
our codomain and ensure that this point also has a corresponding loop:

\begin{code}
  Circleelim : (Z : Type0) (zb : Z) (zloop : zb == zb) -> Circle -> Z
\end{code}

As with \oits, the elimination principle should also satisfy certain
computation rules:

\begin{code}
  Circleelimcomppoint  : (Z : Type0) (zb : Z) (zloop : zb == zb)
                          -> Circleelim Z zb zloop base == zb
\end{code}

Apart from computation rules on points, we also need computation rules
on paths, witnessing the fact that every function defined in type
theory respects equality:

\begin{code}
  Circleelimcomppath  : (Z : Type0) (zb : Z) (zloop : zb == zb)
                         -> ap (Circleelim Z zb zloop) == zloop
\end{code}

The above rules show us that when we want to define a function |f :
Circle -> Z|, we have to say what |f base| and |ap f loop| should be.

We also need the \emph{dependent} elimination principle on circles,
which is as one would expect:

\begin{code}
  Circleelimdep  : (Z : Circle -> Type0) (zb : Z base) (zloop : zb == zb [Z down loop]) 
                   -> (x : Circle) -> Z x
\end{code}

The computation rule for points is the same and the rule for paths is
almost the same: we only have to replace |ap| with |apd|.

\newpage

\subsection{Propositional truncation}

Apart from having path constructors between point constructors, one
can also have \emph{variables} in the left or right hand sides of the
equations. An example of this is propositional truncation, or
$(-1)$-truncation: the operation that creates a version of a given
type such that it is a \emph{proposition}: every two elements are
regarded as equal. Given |A : Type0|, the propositional truncation of
|A|, called |// A //| is defined by:

\begin{itemize}
\item a point constructor |[ _ ] : A -> // A //|
\item a path constructor |trunc : (x y : // A //) -> x == y|
\end{itemize}

with the elimination principle:

\begin{code}
  Aelim : (Z : Type0) (f : A -> Z) (trunc : (x y : Z) -> x == y) -> // A // -> Z
\end{code}

One might think that it should be enough that the image of |f| has to
be propositional, instead of the whole of |Z| and that the elimination
principle is too strict. However, any |f : A -> Z| can be factored as
|A -> Im f -> Z| where |Im f := (z : Z) times (a : A) times f a == z|
and the function |Im f -> Z| is just the first projection. If we can
show that |Im f| is propositional, then we get |// A // -> Im f| hence
|// A // -> Z|.

\subsection{Torus}

The two examples we have seen so far are special cases of \hits,
called \onehits, as the path constructors describe paths between
points of the type being defined, hence can be called
\emph{\oneconstructors} (with ordinary point constructors being
\emph{\zeroconstructors}). We can also consider adding constructors for
paths between paths. One example of this is the following construction
of the torus, which has:

\begin{itemize}
\item a point constructor |base : Torus|
\item two non-trivial loops |p q : base == base|
\item such that their composition commutes: |t : p trans q == q trans p|
\end{itemize}

In order to eliminate from the torus, we not only need to provide a
base point |zb : Z| with two loops |zp zq : zb == zb|, but also a
proof that the loops commute, \ie a proof of |zp trans zq == zq trans
zp|.

\subsection{Set truncation}

In the above example one sees that the terms that can occur in the
constituents of the equations of higher path constructors are no
longer terms generated by the point constructors that can have
variables in them. They are terms built out of the path constructors
or variables from one level down, which can be combined with the
groupoid operations that come with equalities: transitivity, symmetry
and reflexivity.

One example in which the reflexivity term occurs in a \twoconstructor,
is $0$-truncation, or set truncation, which is given by:

\begin{itemize}
\item a point constructor |[ _ truncend0 : A -> // A ///|
\item a path constructor |trunc0 : (x : // A ///) (p : x == x) -> p == refl|
\end{itemize}

The path constructor forces \uip to hold for the type |// A ///|,
making it a set. If we want to eliminate into |Z|, we need to make
sure that |Z| is a set:

\begin{code}
  A0elim          :   (Z : Type0) 
                      (f : A -> Z)
                      (trunc : (x y : Z) -> (p : x == y) -> p == refl)
                  ->  // A /// -> Z
\end{code}

Just as with propositional truncation, it is actually enough for the
image of |f| to be a set and we can use the factorisation trick to get
the function |// A /// -> Z| we want.

\subsection{Hub-spokes construction}

It has been observed that one actually can do without the higher path
constructors \parencite{Lumsdaine2012}: every $n$-HIT can be reduced to a
\onehit. For example, the disc may be realised as a circle with an
added point constructors (the hub) along with a continuous function of
paths from points on the circle to the hub (the spokes). More
precisely: the disc can be realised as the following \hit:

\begin{itemize}
\item a \zeroconstructor |base : Disc|
\item a \oneconstructor |loop : base == base|
\item a \twoconstructor |fill : loop == refl|
\end{itemize}

The hub and spokes variant of this would be:

\begin{itemize}
\item a \zeroconstructor |base : Disc|
\item a \zeroconstructor |hub : Disc|
\item a \oneconstructor |loop : base == base|
\item a \oneconstructor |spokes : (x : Circle) -> f x == hub|
\end{itemize}

where |f : Circle -> Disc| is defined with |f base := base| and |ap f
loop := loop|. The filling in should be seen as gluing in the cone of
the circle, where the boundary of the circle is glued to the loop of
the disc.

The disc itself is not the most exciting example for this
construction, as it is a contractible type. However, replacing
$n$-constructors by a gluing operation of a cone of an $(n-1)$-sphere
means that we can replace any $n$-constructor by an
$(n-1)$-constructor, where $n > 1$. If we do this iteratively, we see
that we at most need \oneconstructors to describe our \hits.


\section{Containers}
\label{sec:containers}

Before we can start formalising a notion of \hits, we need a better
grip on what \oits are. One way to look at inductive types is as
initial algebras of strictly positive functors. For example, the list
data type can be seen as the initial algebra of the functor (having
fixed some |A : Type0|) |ListFA X = 1 + A times X|. An algebra for
this functor is a type |Z : Type0| along with a function |ListF Z ->
Z|. An initial algebra |List : Type0| with |sup : ListF List -> List|
then satisfies the following universal property for any algebra |theta
: ListF Z -> Z| with |Z : Type0|:

\begin{center}
  \begin{tikzpicture}[description/.style={fill=white,inner sep=2pt}]
    \matrix (m) [matrix of math nodes, 
                row sep=4.5em,
                column sep=3.5em,
                text height=1.5ex,
                text depth=0.25ex]
 { |ListF List| & & |List| \\
   |ListF Z|    & & |Z|    \\ };

  \path[->] (m-1-1) edge[decorate] node[auto]       {|sup|} (m-1-3);
  \path[->] (m-1-1) edge[decorate] node[auto,swap]  {|F (elim theta)|} (m-2-1);
  \path[->] (m-1-3) edge[decorate] node[auto]       {|elim theta|} (m-2-3);
  \path[->] (m-2-1) edge[decorate] node[auto]       {|theta|} (m-2-3);
  \end{tikzpicture}
\end{center}

Unfolding the definition of |ListF| in the type of |sup| and applying
the universal property of sums shows us that |sup| is exactly the
familiar list constructors |nil| and |cons| combined. The existence of
|elim theta| for any |theta| gives us the non-dependent elimination
principle, which in this case, if we unfold the definition of |ListF|,
gives, we see that this is the familiar |fold| operation, albeit in
uncurried form. The commutativity of the diagram, \ie the fact that
|elim theta| is an algebra homomorphism, gives us the computation
rules for |elim theta|.

Initiality also means that two algebras satisfying the universal
property are isomorphic, so we can fix a candidate and talk about
\emph{the} initial algebra of a strictly positive functor.

The condition on functors that they need to be strictly positive is
necessary: if we allow for recursion to happen in negative positions,
we can write terms that do not normalise. We can encode the
non-normalising |(\ x . x x) (\ x . x x)| combinator from the untyped
$\lambda$-calculus using the initial algebra of the functor |F X = X
-> X|. Let us call the initial algebra of |F| |Term|, with its
constructor being |Lam : Term -> Term|.

\begin{code}
  omega : Term -> Term
  omega (Lam x) := x (Lam x)

  Omega : Term
  Omega = omega (Lam omega)
\end{code}

One can formalise the grammar of types in which there are no recursive
occurrences in negative positions, as is done
in~\textcite{Morris2007}. Formalising this grammar has several
problems. Dealing with binders is usually rather involved as one has
to use things such as de Bruijn indices. More importantly, one has the
problem that there are multiple representations of the same type, \eg
the unit type can be described as |`1| or |`1 `+ `0|, etc.

\newpage

Another way to more succinctly formalise the notion of strictly
positive functors is as \emph{containers} \parencite{Abbott2005}: a
container is a pair |S : Type0|, the type of \emph{shapes}, and |P : S
-> Type0|, the type of \emph{positions}, denoted |S lhd P|. The
container then describes the functor |sem(S lhd P) X = (s : S) times
(P s -> X)|, which is called the \emph{extension} of the container |S
lhd P|. The extension operator gives us something of type |Type0 ->
Type0|, given a |Cont|, however we still need to show that this is a
functor. The action on morphisms of a container can be defined as
follows:

\begin{code}
  map : {C : Cont} {A B : Type0} (f : A -> B) -> sem(C) A -> sem(C) B
  map f (s , u) := (s , \ i -> f (u i))
\end{code}

One can then easily show that |sem(C)| is indeed a functor with |map|
as its action on morphisms.

The benefits of containers are that they are easy to formalise in
languages such as Agda. Describing things as the action on morphisms
and natural transformations between containers can be done in a
succinct manner. Containers also have the property that if the
extensions of two containers are equal, then the components of the
containers must be equal as well, so we do not have the problem of the
more syntactic appraoch as mentioned above.

\subsection{Initial algebra of a container}

Containers give us a nice description of strictly positive functors,
but we also need their initial algebras. Suppose |sup : sem(C) WC ->
WC| is an initial algebra of the functor |sem(C)| for some container
|C|, then we have that the following diagram commutes for any other
algebra |theta : sem(C) Z -> Z|:

\begin{center}
  \begin{tikzpicture}
    \node (CWC)               {|sem(C) WC|};
    \node (CZ) [below of=CWC] {|sem(C) Z|};
    \node (WC) [right of=CWC] {|WC|};
    \node (Z)  [below of= WC] {|Z|};
    
    \draw[->] (CWC) to node {|sup|} (WC);
    \draw[->] (CWC) to node[swap] {|map C (elim theta)|} (CZ);
    \draw[->] (CZ) to node {|theta|} (Z);
    \draw[->] (WC) to node {|elim theta|} (Z);
  \end{tikzpicture}
\end{center}

If we unfold the definition of |sem(C)| we get the following:

\begin{itemize}
\item Term introduction: |sup : (s : S) times (P s -> WC) -> WC|

\item Elimination principle: |elim : {Z : Type0} (theta : s : S times
  (P s -> Z) -> WC -> Z|

\item Computation rule: for every |s : S|, |u : P s -> WC| and algebra
  |theta : (s : S) times (P s -> Z) -> Z| we get |elim theta (sup (s,
  u)) = theta (s, \ i -> elim theta (u i))|
\end{itemize}

which is the \emph{W-type} construction from~\textcite{MartinLof1984}.

\newpage

Using this we can define the natural numbers as the initial algebra of
the following container:

\begin{code}
  S : Type0
  S := 1 + 1

  P : Type0
  P (inl tt) := 0
  P (inr tt) := 1
\end{code}

The |zero| and |succ| constructors can be defined as follows:

\begin{code}
  zero : WC
  zero := sup (inl tt) exfalso

  succ : WC -> WC
  succ n := sup (inr tt) (\ x -> n)
\end{code}

One downside of the above approach is that the constructors of a type
are not unique up to definitional equality, \eg we can define

\begin{code}
  zero' : WC -> WC
  zero' x := sup (inl tt) (\ _ -> x)
\end{code}

For every |x y : Nat|, we have that |zero' x == zero' y|
propositionally but not definitionally. This can lead to situations
where certain terms do not have the type we want it to, as we will see
in \cref{sec:circle}. Ideally, the type checker identifies closed terms
that are equal by function extensionality (such as the terms |\ _ ->
zero| and |\ _ -> succ zero| of type |0 -> WC|), but this has as side
effect that any two terms become definitionally equal under a false
hypothesis, as is described in~\textcite{McBride2010ii}. In such a system,
reducing open terms can go wrong.


\subsection{Natural transformations}

One can think of what a good notion of morphism between containers
should be. Suppose |C0| and |C1| are containers and |X : Type0|, if we
want to define a function |sem(C0) X -> sem(C1) X|, we notice that,
unfolding the definitions, we have to provide two functions:

\begin{itemize}
\item |f : S0 -> S1|, a mapping between the shapes
\item |g : (s0 : S0) -> P1 (f s0) -> P0 s0|, such that we can map the
  positions in the other way around.
\end{itemize}

Let us define the type of container morphisms to be |Mor : Cont ->
Cont -> Type0| with |mkmor : (f : S0 -> S1) (g : (s0 : S0) -> P1 (f
s0) -> P0 s0) -> Mor C0 C1|. The action of the container morphism on a
types can be defined as follows:

\begin{code}
  applymor : Mor C0 C1 -> (X : Type0) -> sem(C0) X -> sem(C1) X
  applymor (mkmor f g) X (s , u) := (f s , \i -> u (g (f s) i))
\end{code}

We will use the notation |m !! x| (where |m : Mor C0 C1| and |x :
sem(C0) X|, for some |X : Type0| and |C0 => C1| for |Mor C0 C1|.

It so happens that container morphisms are in fact natural
transformations. Given |C0 C1 : Container| and |X Y : Type0|, the
following commutes definitionally, where |eta := applymor m| for
some |m : Mor C0 C1|:

\begin{center}
  \begin{tikzpicture}
    \node (C0X)               {|sem(C0) X|};
    \node (C0Y) [below of=C0X] {|sem(C0) Y|};
    \node (C1X) [right of=C0X] {|sem(C1) X|};
    \node (C1Y) [below of=C1X] {|sem(C1) Y|};
    
    \draw[->] (C0X) to node[swap] {|map C0 f|} (C0Y);
    \draw[->] (C1X) to node {|map C1 f|} (C1Y);
    \draw[->] (C0X) to node {|eta X|} (C1X);
    \draw[->] (C0Y) to node {|eta Y|} (C1Y);
  \end{tikzpicture}
\end{center}

We have shown that every container morphism is a natural
transformation. It also the case that every natural transformation
between the extensions of two containers can be described by a
container morphism, as is shown in~\textcite{Abbott2005}.

\subsection{Free monads}

If we want to describe the left and right hand sides of the equations
in a \oneconstructor, we need some way to talk about terms of a data
type with possibly free variables. One representation of this is given
by the free monad of the functor of which the data type at hand is the
initial algebra.

Given a container, we can construct the free monad of the extension of
the container as a new data type |Free|, given parameters |C : Cont|
and |X : Type0|, with point constructors\footnote{This data type can
  easily be described as W-type. Here we will use this notation along
  with pattern matching definitions to improve readability.}:

\begin{itemize}
\item |return : X -> Free C X|
\item |roll : sem(C) (Free C X) -> Free C X|
\end{itemize}

The |join| operation can be defined as follows:

\begin{code}
  join : {C : Cont} {X : Type0} -> Free C (Free C X) -> Free C X
  join {C} (return c)   := c
  join {C} (roll x)  := roll (map C join x)
\end{code}

The above definition does not immediately look like it is structurally
recursive, but if we inline the definition of |map|, it does becomes
the case.

Defining |return| and |join| is of course not enough: one needs to
show that these follow the monad laws. Before we can define the monad
laws, we need to show that |Free C| is a functor for every |C :
Cont|. Instead of defining a new |map| function for this data type and
showing that it satisfies the functor laws, we can instead create a
container out of this. From the extension of a container we can
retrieve the shapes by plugging in the unit type: |sem(S lhd P) 1 = (s
: S) times P s -> 1 == S|. Using this fact, given a container |S lhd
P|, we can produce a new container, where |P*| is defined by
structural recursion:

\begin{code}
    S' : Type0
    S' := Free C 1

    P' : S' -> Type0
    P' (ret tt)        := 1
    P' (roll (s , u))  := (i : P s) times P' (u i)
\end{code}

We can now define an operation |_* : Cont -> Cont|. Using |sem(C *)|
instead of |Free C| means that we can reuse the definition of |map|
for containers and also the definition of natural transformations. We
need to make sure that this operation indeed gives us what we want:
for every |C : Cont| and |X : Type0|, |Free C X == sem(C *) X| must
hold.

The function from |sem(C *) X| to |Free C X| can be defined by
structural recursion on the shapes:

\begin{code}
  star-free : {C : Cont} {X : Type0} -> sem(C *) X -> Free C X
  star-free (ret tt        , m) = ret (m tt) 
  star-free (roll (s , u)  , m) = roll (s , \ i -> star-free (u i , \ j -> m (i , j)))
\end{code}

Going in the other direction is a bit more involved.

\subsubsection{Algebras for a free monad}

The free monads we are working with happen to be
\emph{algebraically-free}: there is an equivalence between the
category of algebras on |sem(C)| and the category of monad algebras on
|sem(C *)|. This fact is witnessed by the two operations:

\begin{code}
  lift : {C : Cont} {Z : Type0} -> (theta : sem(C) Z -> Z) -> sem(C *) Z -> Z
\end{code}

and

\begin{code}
  forget : {C : Cont} {Z : Type0} -> (theta : sem(C *) Z -> Z) -> sem(C) Z -> Z
\end{code}

Note that we are being a bit imprecise in the type of |forget|, the
algebra |theta| passed to |forget| needs to be a \emph{monad} algebra,
\ie it must respect the |join| operation, which means that the
following must commute:

\begin{center}
  \begin{tikzpicture}[description/.style={fill=white,inner sep=2pt}]
    \matrix (m) [matrix of math nodes, 
                row sep=4.5em,
                column sep=3.5em,
                text height=1.5ex,
                text depth=0.25ex]
 { |sem(C *) (sem (C *) X)| & & |sem(C *) X| \\
   |sem(C *) X|    & & |X|    \\ };

  \path[->] (m-1-1) edge[decorate] node[auto]       {|map specialCase theta|} (m-1-3);
  \path[->] (m-1-1) edge[decorate] node[auto,swap]  {|join|} (m-2-1);
  \path[->] (m-1-3) edge[decorate] node[auto]       {|theta|} (m-2-3);
  \path[->] (m-2-1) edge[decorate] node[auto]       {|theta|} (m-2-3);
  \end{tikzpicture}
\end{center}

\newpage

The algebra |theta| must also respect the |return| operation, \ie the
following commutes:

\begin{center}
  \begin{tikzpicture}
    \node (X) {|X|};
    \node (T)  [right of=X] {|sem (C *) X|};
    \node (X') [below of=T] {|X|};

    \draw[->] (X) to node {|return|} (T);
    \draw[->] (T) to node {|theta|} (X');
    \draw[->] (X) to node[swap] {|id|} (X');
  \end{tikzpicture}
\end{center}

One can easily show that |forget (lift theta) x == theta x| for any
|theta : sem (C) X -> X| and |x : sem( C *) X| by case distinction and
$\beta$-reduction. Showing that |lift (forget theta) x == theta x| for
|theta : sem (C *) X -> X| and |x : sem(C) X| is a bit more involved
and needs to use the fact that |theta| is a monad algebra. The
functions |lift| and |forget| give the object part of the functors
that witness the equivalence of the categories.

As we have previously mentioned, the free monad of a functor can be
seen as the type of terms of the initial algebra of the same functor,
but possibly with free variables. We have an instantiation operation
|inst| that takes a substitution |v : X -> W C| and a term with free
variables |x : sem(C *) X| and produces a |W C| by the following
composition:

\begin{center}
  \begin{tikzpicture}
    \matrix (m) [matrix of math nodes, 
                row sep=4.5em,
                column sep=3.5em,
                text height=1.5ex,
                text depth=0.25ex]
    { |sem(C *) X| & & |sem(C *) (W C)| & & |W C| \\ } ;

    \draw[->] (m-1-1) edge[decorate] node[auto] {|map (C *) v|} (m-1-3);
    \draw[->] (m-1-3) edge[decorate] node[auto] {|lift sup|}    (m-1-5);
  \end{tikzpicture}
\end{center}

We also have a ``generalisation'' operation that goes in the other
direction:

\begin{code}
    gen : W C -> Free C X
    gen (sup x) := roll (map C gen x)
\end{code}

which satisfies the property that for every value |x : W C| and
instantation |v : X -> W C|, we have |inst v (gen x) == x|.

\section{Construction of \onehits}
\label{sec:construction-onehits}

We want to extend the concept of container to also be able to describe
the data needed for the \emph{path} constructors:

\begin{itemize}
\item |C0 : Cont| for the point constructors
\item |C1 : Cont| where the shapes |S1 : Type0| represent the shapes
  of the path constructors. The positions |P1 : S1 -> Type0| give the
  type of \emph{variables} for every shape.
\item |l r : (s : S1) -> sem(C0 *) (P1 s)| describe the left and right
  hand side of the path constructors, where |sem(C0 *) (P1 s)| should
  be seen as terms constructed using |W C0| with free variables coming
  from |P1 s|.
\end{itemize}

\newpage

The point and path constructors are then as follows, if we call the
type we are defining |H|:

\begin{itemize}
\item |sup0 : sem(C0) H -> H|
\item |sup1 : (s : S1) -> (v : P1 s -> H) -> inst v (l s) == inst v (r s)|
\end{itemize}

The version of |inst| that we need here is a bit different from the
one we have defined previously: instead of doing |lift sup|, we now do
|lift sup0|. Apart from this, the behaviour is essentially the same.

The argument of type |P1 s -> H| of the path constructor |sup1| can be
interpreted as being the assignment of the free variables.

To eliminate out of a \onehit, we need to say what one needs to be
done with the point constructors and show that this is done in a way
that respects the \oneconstructors. This leads us to the following
elimination principle:

\begin{code}
  elim  :  (Z : Type0)
           (theta : sem(C0) Z -> Z)
           (rho :  (s : S1) -> (v : P1 s -> Z) -> 
                   lift theta (map (C0 *) v (l s)) == lift theta (map (C0 *) v (r s)))
        -> H -> Z
\end{code}

This principle should satisfy the following computation rule on point
constructors definitionally, given |m : sem(C0) H|:

\begin{code}
  elim Z theta rho (c0 m) = theta (map C0 (elim Z theta rho) m)
\end{code}

Just as the above computation rule explains how to reduce the
elimination principle applied to a canonical \emph{point}, we want a
computation rule that explains how to reduce the elimination principle
applied to a canonical \emph{path}. Just as the above refers to the
algebra |theta| on points, we expect the path computation rule to
refer to the ``algebra'' on paths. Both |sup1| as well as |rho| expect a
substitution, but |rho| expects a substitution into |Z| instead of
|H|, but any |v : X -> H| induces a |v' : X -> Z| by post-composition
with |elim Z theta rho|. Using this, a somewhat sensible candidate for
the path computation rule is;

\begin{code}
  ap (elim Z theta rho) (sup1 s v) == rho s (\ x -> elim Z theta rho (v x))
\end{code}

However, the substitution However, this does not type check, as the
term on the left hand side has type |elim Z theta rho (inst v (l s))
== elim Z theta rho (inst v (r s))|, whereas the right hand side has
type |lift theta (C0 *) (\ x -> elim Z theta rho (v x)) (l s) == lift
theta (map (C0 *) (\ x -> elim Z theta rho (v x)) (r s))|.

This problem can be solved, but with this presentation it is difficult
to see what is actually going ``wrong'' with the types, hence the
discussion of this is postponed until \cref{sec:altern-constr}.

\newpage

\subsection{Examples}

\subsubsection{Circle}
\label{sec:circle}

As mentioned previously, the circle can be inductively defined as a
type with one point constructor (|base|) and one path constructor
(|loop : base == base|). 

\begin{itemize}
\item |C0 := 1 lhd (\ s -> 0)|, \ie one point constructor without any recursion.
\item |C1 := 1 lhd (\ s -> 0)|, \ie one point constructor without any variables or arguments.
\end{itemize}

We can now define |base := sup0 (tt , exfalso)|, which we need in the
data for the path constructor:

\begin{itemize}
\item |l s := gen base|
\item |r s := gen base|
\end{itemize}

We would like to be able to define |loop| as well with the following
type:

\begin{code}
  loop : base == base
  loop := sup1 tt exfalso
\end{code}

However, this does not type check as |sup1 tt exfalso| has type |inst
exfalso (gen base) == inst exfalso (gen base)|. We can prove that
|inst exfalso (gen base) == base|.

\subsubsection{Propositional truncation}

Propositional truncation of a type |A : Type0| is given by one point
constructor |A -> // A //| and one path constructor |(x y : // A //)
-> x == y|. This means that |C0 := A lhd (\ s -> 0)| and |S1 := 1|
with |P1 x := Bool|. The truncation equation is given by |l x := sup
(inl true) exfalso| and |r x := sup (inl false)|. From this data we
can define |[ x ] := sup0 x exfalso| and |trunc x y := sup1 tt (\ b ->
if b then x else y) exfalso|. Note that in this case |trunc : (x y :
// A //) -> x == y| does give us the right type straight away, as both
sides of the equation consist of a single variable.

\subsection{Alternative construction}
\label{sec:altern-constr}

An alternative, more conceptual presentation of \onehits, proposed by
Paolo Capriotti, is as follows:

\begin{itemize}
\item |C0 : Cont| for the point constructors
\item |C1 : Cont| for the path constructors
\item |left right : sem(C1) => sem(C0 *)| natural transformations
  describing the result types of the path constructors.
\end{itemize}

\newpage

The constructors of the type |H| that we are defining, are:

\begin{itemize}
\item |sup0 : sem(C0) H -> H|
\item |sup1 : (x : sem(C1) H) -> lift sup0 (left !! x) == lift sup0 (right !! x)|
\end{itemize}

The description of the data looks similar to the previous approach,
except that the constituents of the equations are given in a seemingly
different form. However, providing a natural transformation |sem(C1)
=> sem(C0 *)| boils down to giving a function |(s : S1) -> sem(C0 *)
(P1 s)|: unfolding the definition of |sem(C0 *) (P1 s)| we get:

\begin{code}
  l : (s : S1) -> (s* : S0*) times (P0* -> P1 s)
\end{code}

which is the same as giving two functions:

\begin{code}
  l0 : S1 -> S0*
  l1 : (s : S1) -> P0* (l0 s) -> P1 s
\end{code}

We now need to show that |lift sup0 ((mkmor l0 l1) !! (s , v)) == inst v
(l s)| (and similarly for |r|):

\begin{code}
  lift sup0 ((mkmor l0 l1) !! (s , v))       ==
  lift sup0 (l0 s , \ i -> v (l1 (l0 s) i))  ==
  lift sup0 (map (C0 *) v (l0 s, l1 (l0 s))  ==
  lift sup0 (map (C0 *) v (l s))             ==
  inst v (l s)
\end{code}

The elimination principle is given by, which is also equivalent to the previous principle:

\begin{code}
  elim  :  (Z : Type0)
           (theta : sem(C0) Z -> Z)
           (rho :  (x : sem(C1) Z) -> lift theta (left !! x) == lift theta (right !! x))
        -> H -> Z
\end{code}

along with the computation rule for points:

\begin{code}
  elim Z theta rho (sup0 m) = theta (map C0 (elim Z theta rho) m)
\end{code}

Of course, we still have the problem of defining our path computation rule as:

\begin{code}
  ap (elim Z theta rho) (sup1 m) == rho (map C0 (elim Z theta rho) m)
\end{code}

\newpage

With this representation, as opposed to the previous approach, it
becomes a bit clearer what diagrams have to commute in order for this
to work. We have:

\begin{code}
  ap (elim Z theta rho) (sup1 m) : 
    elim Z theta rho (lift sup0 (left !! m)) == elim Z theta rho (lift sup0 (right !! m))
\end{code}

versus

\begin{code}
  rho (map C0 (elim Z theta rho) m) :
    lift theta (left !! map C0 (elim Z theta rho) m) == lift theta (right !! map C0 (elim Z theta rho) m) 
\end{code}

Asserting the equality to both left hand sides is the same as
asserting the commutativity of the following diagram:

\begin{center}
  \begin{tikzpicture}[description/.style={fill=white,inner sep=2pt}]
    \matrix (m) [matrix of math nodes, 
                row sep=4.5em,
                column sep=3.5em,
                text height=1.5ex,
                text depth=0.25ex]
 { |sem(C1) H| & & |sem(C0*) H| & & H \\
   |sem(C1) Z| & & |sem(C0*) Z| & & Z \\
 };

 \path[->] (m-1-1) edge[decorate] node[auto] {|leftH|} (m-1-3);
 \path[->] (m-1-3) edge[decorate] node[auto] {|lift sup0|} (m-1-5);
 \path[->] (m-1-1) edge[decorate] node[auto, swap] {|map C0 (elim theta rho)|} (m-2-1);
 \path[->] (m-1-5) edge[decorate] node[auto] {|elim theta rho|} (m-2-5);
 \path[->] (m-2-1) edge[decorate] node[auto, swap] {|leftZ|} (m-2-3);
 \path[->] (m-2-3) edge[decorate] node[auto, swap] {|lift theta|} (m-2-5);
  \end{tikzpicture}
\end{center}

We can fill in the diagram by adding an arrow |sem(C0 *) H -> sem(C0
*) Z|, namely |map (C0 *) (elim theta rho)|:

\begin{center}
  \begin{tikzpicture}[description/.style={fill=white,inner sep=2pt}]
    \matrix (m) [matrix of math nodes, 
                row sep=4.5em,
                column sep=3.5em,
                text height=1.5ex,
                text depth=0.25ex]
 { |sem(C1) H| & & |sem(C0*) H| & & H \\
   |sem(C1) Z| & & |sem(C0*) Z| & & Z \\
 };

 \path[->] (m-1-1) edge[decorate] node[auto] {|leftH|} (m-1-3);
 \path[->] (m-1-3) edge[decorate] node[auto] {|lift sup0|} (m-1-5);
 \path[->] (m-1-1) edge[decorate] node[auto, swap] {|map C0 (elim theta rho)|} (m-2-1);
 \path[->] (m-1-3) edge[decorate] node[auto, swap] {|map (C0*) (elim theta rho)|} (m-2-3);
 \path[->] (m-1-5) edge[decorate] node[auto] {|elim theta rho|} (m-2-5);
 \path[->] (m-2-1) edge[decorate] node[auto, swap] {|leftZ|} (m-2-3);
 \path[->] (m-2-3) edge[decorate] node[auto, swap] {|lift theta|} (m-2-5);
  \end{tikzpicture}
\end{center}

The resulting square on the left holds by naturality. The square on
the right is the statement that |elim theta rho| is an algebra
homomorphism from |lift sup0| to |lift theta|. We can prove this if we
substitute |sem(C0 *) H| and |sem(C0 *) Z| with |Free C H| and |Free C
X| respectively. After this substitution, the commutativity can be
shown to hold by induction on |Free C H|.

\begin{researchdir}
  A lot of the above has been formalised in Agda. However, there are
  still some details missing, most notably a complete proof of |Free C
  X| and |sem(C *) X| being equal for every |X : Type0|. Finishing the
  Agda formalisation and documenting it properly is an important
  research direction.
\end{researchdir}

\subsection{Limitations of the construction}
\label{sec:limit-constr}

With ordinary strictly positive types, we can define types such as
rose trees: given a type |A : Type0|, we have:

\begin{itemize}
\item |node : A -> List (RoseTree A) -> RoseTree A|
\end{itemize}

It is perfectly okay to put apply a recursive occurrence to a strictly
positive functor. The same, however, cannot be done with our \onehit
construction, \eg we cannot define the type |A| given by the point constructor:

\begin{itemize}
\item |c : // A // -> A|
\end{itemize}

For this to work we would need to find a |S : Type0| and a |P : S ->
Type0| such that for every |X : Type0| we have |((s : S) times P s -> X)
== // X //|, which does not seem to be the case.

\begin{researchdir}
  Find out how we can change our construction such that we can define
  types such as the above example.
\end{researchdir}

\section{Construction of $2$-HITs}
\label{sec:construction-2-hits}

In theory having only \onehits should be enough, since we have some
sort of way to translate any higher definition to the lower one: the
hub-and-spokes construction. In order to make this construction
precise, we still need a formal way to talk about $n$-HITs in general.

A start would be to find a way to define $2$-HITs along with a
function that, given a definition of a $2$-HIT, produces a definition
of a \onehit, along with a proof that the interpretations of both
definitions are equal.

To be able to define \twoconstructors, we need to be able to talk
about paths between paths between points. To be able to do this we
need the free groupoid operation on relations: given a type |X :
Type0| and a relation on |R : X -> X -> Type0|, we can define the
indexed \onehit |FreeGroupoid : X -> X -> Type0| as follows:

\begin{itemize}
\item |return : (x y : G) -> R x y -> FreeGroupoid x y|
\item |trans' : {x y z : G} -> FreeGroupoid x y -> FreeGroupoid y z -> FreeGroupoid x z|
\item |sym : {x y : G} -> FreeGroupoid x y -> FreeGroupoid y x|
\item |refl : {x : G} -> FreeGroupoid x x|
\end{itemize}

In order for |FreeGroupoid| to be a groupoid, we need the following
path constructors:

\begin{itemize}
\item
  \begin{code}
  assoc  :   {x y z w : G}
             (p : FreeGroupoid x y)
             (q : FreeGroupoid y z)
             (r : FreeGroupoid z w)
         ->  trans' (trans' p q) r == trans' p (trans' q r)
  \end{code}
\item
  \begin{code}
  reflunitl    :   {x y : G}
                   (p : FreeGroupoid x y)
               ->  trans' refl p == p
  \end{code}
\item
  \begin{code}
  reflunitr    :   {x y : G}
                   (p : FreeGroupoid x y)
               ->  trans' p refl == p
  \end{code}
\item
  \begin{code}
  symrefl   :   {x y : G}
                (p : FreeGroupoid x y)
            ->  sym (sym p) == p
  \end{code}
\end{itemize}

\begin{researchdir}
  Find a way to formalise indexed \onehits, such as the |FreeGroupoid|
  example above.
\end{researchdir}

\begin{researchdir}
  Find a way to define $2$-HITs, along with a formalisation of the
  hub-and-spokes translation from $2$-HITs to \onehits, together with
  a proof of its correctness.
\end{researchdir}

\section{Higher inductive-recursive types}
\label{sec:high-induct-recurs}

When implementing type theory in type theory, a common way to describe
the universe of types, is by an inductive-recursive definition. One
defines a data type of codes of types |U : Type0| together with the
interpretation function |El : U -> Type0|, \eg:

\begin{itemize}
\item |sig  : (A : U) -> (El A -> U) -> U|
\item |pi   : (A : U) -> (El A -> U) -> U|
\item |`0 : U|
\item |`1 : U|
\end{itemize}

Along with |El|:

\begin{code}
  El  (sig A B)  = (a : El A) times El (B a)
  El  (pi A B)   = (a : El A) -> El (B a)
  El  `0         = 0
  El  `1         = 1
\end{code}

In \hott, we would like this universe to be univalent: any two codes
|x y : U| should be equal if their interpretations are equal. This can
be achieved by adding a path constructor, as proposed
in~\textcite{Shulman2014}:

\begin{itemize}
\item |ua : (x y : U) -> El x == El y -> x == y|
\end{itemize}

Since |El| is now a function out of a \hit, we also have to specify
what |ap| does on on |ua|, so for any |x y : U| and |p : El x == El
y|, we define:

\begin{itemize}
\item |ap El (ua x y p) == p|
\end{itemize}

Using this we can show that for any |x y : U|, we have an equivalence
between |El x == El y| and |x == y|, so if |Type0| is univalent, then
so is |U|.

\begin{researchdir}
  Find and formalise a notion of $1$-higher inductive-recursive types.
\end{researchdir}



\chapter{Dependent pattern matching}
\label{ch:patmatch}

In functional programming languages such as Haskell, one defines
functions on inductive types by using pattern matching. For example,
we can define the Ackermann function as follows:

\begin{code}
  Ack 0      n      = S n
  Ack (S m)  0      = Ack m (S 0)
  Ack (S m)  (S n)  = Ack m (Ack (S m) n)
\end{code}

When defining functions on inductive types in \mltt, we only have the
type its \emph{elimination principle} at our disposal. The
(non-dependent) elimination principle for the natural numbers is the
following:

\begin{code}
  Natelim : (Z : Type0) -> Z -> (Z -> Z) -> Nat -> Z
\end{code}

with computation rules

\begin{code}
  Natelim mz ms 0      = mz
  Natelim mz ms (S n)  = ms (Natelim mz ms n)
\end{code}

The definition of |Ack| using |Natelim| looks as follows:

\begin{code}
  Ack : Nat -> Nat -> Nat
  Ack = 
    Natelim  (Nat -> Nat) 
             (\ n -> S n)
             (\ ackm -> Natelim  Nat 
                                 (ackm (S Z)) 
                                 (\ ackSmn -> ackm ackSmn))
\end{code}

which is less readable then our original definition. It would be nice
if we added pattern matching to \mltt. However, we do need to be
careful when we do this. We have to be sure that our pattern matching
definitions are total. As it turns out, it is sufficient
\parencite{Coquand1992} to check that the patterns are \emph{covering} and
that the recursive calls are done on \emph{structurally smaller}
arguments of the patterns. For example, if we were pattern matching on
a list, the recursive calls in the |cons x xs| case must be done on
|xs|. This ensures that the recursion eventually reaches a base case
and the definition yields a terminating function.

\section{Inductive families}

In dependently-typed languages we can \emph{families} of inductive
types indexed by some other type, so-called \emph{inductive
  families}. We may want to define a family of list types, indexed by
the length:

\begin{code}
  data Vec (A : Type0) : Nat -> Type0 where
    nil   : Vec A 0
    cons  : A -> (n : Nat) -> Vec A n -> Vec A (S n)
\end{code}

|Vec| is a family of types \emph{parametrised} by |A : Type0| and
\emph{indexed} by |Nat|. Parameters are distinguished from indices in
that they occur uniformly in the result type of every constructor. In
the |Vec| example, the |A| occurs uniformly in both the result type of
|nil| as well as |cons|, whereas the index of type |Nat| is |0| in the
|nil| case and |S n| in the |cons| case.

Indices are a useful way of encoding invariants in our data types. We
can get a lot more information about a value we get just from its
type. If we for example get a value |l : Vec A (S n)| for some |A :
Type0| and |n : Nat|, we know that |l| cannot be |nil|, as that would
not type check. This kind of information can also help us when we
write functions on inductive families. Say we want to define the
function |head| on vectors, a definition that only makes sense on
non-empty vectors. We can specify this constraint in the type as
follows: |head : (A : Type0) (n : Nat) -> Vec A (S n) -> A|. As
mentioned before, we should only have to define what to do in the
|cons| case, as the |nil| case is impossible. The form of pattern
matching that takes into account the extra information one gets from
the indices as they occur in the type signature of the function, is
called \emph{dependent pattern matching}.

With dependent pattern matching, we can write |head| as follows:

\begin{code}
  head : (A : Type0) (n : Nat) -> Vec A (S n) -> A
  head A .(S n) (cons x n xs) = x
\end{code}

The dot in the pattern |.(S n)| indicates that there is no other
possible well-typed pattern other than |S n| for that argument. The
definition is also complete: the |nil| case is impossible as we have
previously mentioned.

\newpage

\section{\Uip}

One important example of an indexed family is the identity type:

\begin{code}
data Id (A : Type0) (x : A) : A -> Type0 where
  refl : Id A x x
\end{code}

An inhabitant of |Id A x y| constitutes a proof that the terms |x| and
|y| are equal. Note that |refl : Id A x y| only type checks if |x| and
|y| are definitionally equal. To increase readability, we will
sometimes denote |Id A x y| by |x == y|, leaving the type argument
implicit. For \emph{definitional} equality between two terms |x| and
|y|, we use the notation |x = y|.

Given this definition of equality, it might lead one to think that if
we have a proof |p : Id A x y|, it is necessarily unique. In fact,
using dependent pattern matching, we can easily prove this:

\begin{code}
  uip : (A : Type0) (x y : A) (p : x == y) -> p == refl
  uip A x .x refl = refl
\end{code}

Proving this using only the elimination principle of identity types
turns out to be impossible: one can construct models of \mltt with
identity types in which the \uip property does not hold for every
type \parencite{Hofmann1998}. In \hott, we are specifically interested
in the models that violate this principle, hence dependent pattern
matching in its unrestricted form is incompatible with \hott. We hope
to uncover what the root of this incompatibility is and whether we can
find a variation of dependent pattern matching that is not at odds
with \hott.

\section{Parametrising inductive families}

To get a better understanding of indexed families and dependent pattern
matching, we will translate some definitions to a non-indexed,
parametrised family, using identity types. With identity types, one
can factor out the ``indexedness'' of a family and make it more
explicit what is going on when we try to eliminate out of such a
family.

For example, we can translate the vector type as follows:

\begin{code}
  data Vec' (A : Type0) (n : Nat) : Type0 where
    nil   : n == 0 -> Vec A n
    cons  : A -> (m : Nat) -> Vec A m -> n == S m -> Vec A n
\end{code}

\newpage

If we now try to define |head| by pattern matching on |Vec' A (S n)|,
we get the following:

\begin{code}
  head : (A : Type0) (n : Nat) -> Vec' A (S n) -> A
  head A n (nil p) = ?
  head A n (cons x m xs q) = x
\end{code}

The type of |p| is |S n == 0|, which is can be shown to be the empty
type, so the |nil| case can be ignored. Note that we also have |q : n
== S m|, corresponding to the dot pattern |.(S n)| in the previous
definition of |head|.

\section{Correctness of dependent pattern matching}

It has been shown in~\textcite{Goguen2006} that dependent pattern matching
is correct if one assumes \uip: one can translate a definition written
using dependent pattern matching into one that only makes use of the
elimination principles of the data types being used, possibly along
with use of \uip.

In~\textcite{Cockx2014}, the authors describe a criterium under which
dependent pattern matching is safe, even when one does not assume
\uip. However, the proof that the criterium is sufficient is rather
syntactic.

\begin{researchdir}
  Give an internal proof of the correctness of a restricted form of
  dependent pattern matching. In order to do this, one has to first
  internalise a right notion of inductive family and then internalise
  a notion of dependent pattern matching. If the latter can be done by
  only using the elimination principles of the data types at hand, we
  have shown that the form of dependent pattern matching is correct.

  Internalising this might also help giving insight in what happens
  semantically.
\end{researchdir}

\newpage

\section{Other inconsistencies with dependent pattern matching}

Another inconsistency in Agda's pattern matching mechanism has been
uncovered on the Agda mailing list~\parencite{McBride2014}. Suppose we have a
type |Box| with one constructor:

\begin{itemize}
\item |wrap : (0 -> Box) -> Box|
\end{itemize}

Given that there is only one function |0 -> Box|, we notice that |Box|
itself must be a proposition. In fact, we have an equivalence between
|Box| and |0 -> Box|. If we have univalence or just propositional
extensionality, we have a proof |pf : Box == (0 -> Box)|. Consider the
following function:

\begin{code}
  noo : (X : Type0) -> (Box == X) -> X -> 0
  noo .Box refl (wrap f) = noo (0 -> Box) pf f
\end{code}

Note that we first should pattern match in the |Box == X| argument,
which forces |X| to be |Box|, allowing us to pattern match on the
third argument, which now has type |Box|. We can then recursively call
|noo| on the |f : 0 -> Box| we get from pattern matching, which makes
the definition look structurally recursive.

Using |noo| we can now define an inhabitant of |0| as follows:

\begin{code}
  bad : 0
  bad = noo (0 -> Box) pf exfalso
\end{code}

\begin{researchdir}
  Find out whether the above inconsistency is because Agda does not
  follow the rules described in~\textcite{Goguen2006} closely enough or if
  the paper has some implicit hypotheses that are needed for the
  proofs to go through.
\end{researchdir}

\chapter{PhD plan}
\label{cha:phd-outline}

My current goal is to finish up the first attempt at finding a
universal construction for \onehits, specifically finishing up and
properly documenting the Agda formalisation. Apart from this, there
are some ways the construction can be extended. One limitation of the
current approach has been discussed in \cref{sec:limit-constr}. We
should look into why these type of examples cannot be expressed and
look for possible fixes to the universal construction to make this
possible. Other extensions that have been discussed are extending the
constructon to \twohits (\cref{sec:construction-2-hits}), indexed
\onehits (\cref{sec:construction-2-hits}) and $1$-higher
inductive-recursive types (\cref{sec:high-induct-recurs}).

Besides describing \hits, I also want to look into pattern matching in
the context of \hott. One interesting research direction in this
context is pattern matching on \hits. We currently have to write our
definitions on \hits using their elimination principles, which of
course suffers from the same problems as in the case of
\oits. Especially when writing binary functions on a \hit, showing
that the given algebra on points respects the path constructors can
quickly become very involved. We would like some form of pattern
matching to describe the computation rules for the path constructors,
similar to pattern matching on point constructors.

Another interesting topic is to give an explanation of pattern
matching, in particular \emph{dependent} pattern matching in terms of
\hott. It has been shown \parencite{Goguen2006} that dependent pattern
matching definitions can be translated to definitions that only make
use of the appropriate elimination principles. The problem with this
translation is that it relies on \uip to hold, which makes it
unsuitable for \hott. \textcite{Cockx2014} give conditions under which
the translation does not need \uip. As these approaches are very
syntactic, it would be nice to give a more semantic account of
dependent pattern matching in \hott terms. Instead of a external
translation procedure, it would be nice to have an internal account of
dependent pattern matching which perhaps could be achieved using
generic programming techniques.

\section{Outline}

\begin{itemize}
\item \Hits
  \begin{itemize}
  \item Examples of \hits
  \item Universal \onehit
    \begin{itemize}
    \item First approach
    \item Limitations of first approach
    \item Overcoming the limitations
    \end{itemize}
  \item Universal \twohit
    \begin{itemize}
    \item Formalising the hub-spokes construction
    \end{itemize}
  \item Indexed \onehits
  \item Inductive-recursive \onehits
  \end{itemize}
\item Dependent pattern matching
  \begin{itemize}
  \item Examples of dependent pattern matching
  \item Issues with dependent pattern matching
  \item Internalising dependent pattern matching
  \item Pattern matching on \hits
  \end{itemize}
\end{itemize}

\section{Planning}

\begin{itemize}
\item 2014
  \begin{itemize}
  \item \textbf{June--November:}
    \begin{itemize}
    \item Finish up and properly documenting the Agda formalisation
      of the current approach to a universal \onehit.
    \item Start working out a similar approach to a universal \twohit.
    \item Formalise the hub-spokes construction from \twohits to
      \onehits.
    \item Look at limitations of current approach to a universal
      \onehit.
    \item Look at formalising indexed \onehits.
    \item Look at formalising inductive-recursive \onehits.
    \end{itemize}
  \item \textbf{December:} internalising dependent pattern matching
  \end{itemize}
\item 2015
  \begin{itemize}
  \item \textbf{January--March:} internalising dependent pattern matching
  \item \textbf{April--July:} (dependent) pattern matching on \hits
  \end{itemize}
\end{itemize}

\printbibliography

\end{document}

